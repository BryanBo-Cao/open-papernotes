# open-papernotes

This idea of paper notes was inspired by [Hongjie Peng](https://scholar.google.com/citations?user=vr8W0MgAAAAJ&hl=en), and the methodology of taking notes was inspired by [Qi Zeng](https://github.com/pkuzengqi), [Daniel Seita](https://github.com/DanielTakeshi/Paper_Notes), [Adrian Colyer](https://blog.acolyer.org/about/) and [Denny Britz](https://github.com/dennybritz/deeplearning-papernotes).

This repo contains my notes for research papers that I've read.

#### Rubrics from ```Y2021```:
Papers are numbered on a ```1``` to ```5``` scale in the following aspects:
- ```C```: I understand the research problem and **C**hallenges.
- ```M```: I understand the **M**ain idea and the main contributions to the literature.
- ```E```: I am familiar with the details of **E**xperiments.
- ```L```: I am able to find out the **L**imitations of the proposed method.

#### Rubrics before ```Y2021```:
Papers are numbered on a (1) to (5) scale where

- (1) means I have only barely skimmed it or listened to the presentation.
- (2) means (1) + I understand the main idea and the main contributions to the literature.
- (3) means (2) + related works.
- (4) means (3) + details of the experiments.
- (5) means (4) + I feel confident that I understand almost everything about the paper.

In addition, (0) is used simply to indicate papers that are in the "toread" list.

Each note contains ```C```, ```M```, ```L``` in ```Rubrics from Y2021``` and **takeaways**.

In terms of articles or research posts that are not published in peer review conference or journel, they are numbered on a (1) to (5) scale as well to indicate the extent to which I understand the content.

All papers are included in my previous repo [papers](https://github.com/BryanBo-Cao/papers), which is set to private since it contains papers that need purchased. However, the original papers that are public available without purchasing can be found in the link along with the title of the paper.

---

### Recent Notes
Y2021 Mar
- Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking ```C1M1E1L1``` [[paper](https://arxiv.org/pdf/1609.01775.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/others/Performance%20Measures%20and%20a%20Data%20Set%20for%20Multi-Target%2C%20Multi-Camera%20Tracking.pdf)]
- Ear-AR: Indoor Acoustic Augmented Reality on Earphones, MobiCom 2020 ```C1M1E1L1``` [[paper](https://synrg.csl.illinois.edu/papers/ear-ar_mobicom20.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/MobiCom/MobiCom_2020/Ear-AR-%20Indoor%20Acoustic%20Augmented%20Reality%20on%20Earphones.pdf)]
- Multimodal Intelligence: Representation Learning, Information Fusion, and Applications, SP 2020 ```M1``` [[paper](https://arxiv.org/pdf/1911.03977.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/journals/SP/SP_2020/Multimodal%20Intelligence-%20Representation%20Learning%2C%20Information%20Fusion%2C%20and%20Applications.pdf)]
- Towards 3D Human Pose Construction Using WiFi, MobiCom 2020 ```C1M1E1L1``` [[paper](https://dl.acm.org/doi/10.1145/3372224.3380900)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/MobiCom/MobiCom_2020/Towards%203D%20Human%20Pose%20Construction%20Using%20WiFi.pdf)]
- Dense Multimodal Fusion for Hierarchically Joint Representation, ICASSP 2019 ```C3M2E2L2``` [[paper](https://ieeexplore.ieee.org/document/8683898)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ICASSP/ICASSP_2019/Dense%20Multimodal%20Fusion%20for%20Hierarchically%20Joint%20Representation.pdf)]
- RGB-W: When Vision Meets Wireless, ICCV 2015 ```C2M2E1L1``` [[paper](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Alahi_RGB-W_When_Vision_ICCV_2015_paper.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ICCV/ICCV_2015/RGB-W-%20When%20Vision%20Meets%20Wireless.pdf)]
- Simultaneous Identification and Tracking of Multiple People using Video and IMUs, CVPRW 2019 ```C2M2E2L2``` [[paper](https://openaccess.thecvf.com/content_CVPRW_2019/papers/BMTT/Henschel_Simultaneous_Identification_and_Tracking_of_Multiple_People_Using_Video_and_CVPRW_2019_paper.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CVPR/CVPRW_2019/Simultaneous%20Identification%20and%20Tracking%20of%20Multiple%20People%20using%20Video%20and%20IMUs.pdf)]
- Accurate Long-Term Multiple People Tracking Using Video and Body-Worn IMUs, TIP 2020 ```C2M2E1L1``` [[paper](https://www.tnt.uni-hannover.de/papers/data/1475/09166762.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/trans/TIP/TIP_2020/Accurate%20Long-Term%20Multiple%20People%20Tracking%20Using%20Video%20and%20Body-Worn%20IMUs.pdf)]
- S3K: Self-Supervised Semantic Keypoints for Robotic Manipulation via Multi-View Consistency, CoRL 2020 ```C2M2E1L1``` [[paper](https://drive.google.com/file/d/15lZ0nPZeV5zFY2heTU2ZZUpaXQkuJPH8/view)] [[website0](https://corlconf.github.io/paper_96/)] [[website1](https://sites.google.com/view/2020-s3k/home)] [[video](https://www.youtube.com/watch?v=FB3p-LUEOBE&feature=emb_logo)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CoRL/CoRL_2020/S3K-%20Self-Supervised%20Semantic%20Keypoints%20for%20Robotic%20Manipulation%20via%20Multi-View%20Consistency.pdf)]
- Text-to-Image Generation Grounded by Fine-Grained User Attention, WACV 2021 ```C1M1E1L1``` [[paper](https://openaccess.thecvf.com/content/WACV2021/papers/Koh_Text-to-Image_Generation_Grounded_by_Fine-Grained_User_Attention_WACV_2021_paper.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/WACV/WACV_2021/Text-to-Image%20Generation%20Grounded%20by%20Fine-Grained%20User%20Attention.pdf)]
- Multi-modal Discriminative Model for Vision-and-Language Navigation, ACL 2019 ```C1M1E1L1``` [[paper](https://www.aclweb.org/anthology/W19-1605.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ACL/ACL_2019/Multi-modal%20Discriminative%20Model%20for%20Vision-and-Language%20Navigation.pdf)]
- Hierarchical Self-Attention Network for Action Localization in Videos, ICCV 2019 ```C2M3E1L1``` [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Pramono_Hierarchical_Self-Attention_Network_for_Action_Localization_in_Videos_ICCV_2019_paper.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ICCV/ICCV_2019/Hierarchical%20Self-Attention%20Network%20for%20Action%20Localization%20in%20Videos.pdf)]

Y2021 Feb
- Focal Visual-Text Attention for Visual Question Answering, CVPR 2018 ```C1M1E1L1``` [[paper](https://www.cs.cmu.edu/~junweil/camera_ready/cvpr18.pdf)] [[website](https://memexqa.cs.cmu.edu/fvta.html)] [[video](https://www.youtube.com/watch?time_continue=4292&v=TBOnKekODCI&feature=emb_title)] [[code](https://github.com/JunweiLiang/FVTA_MemexQA)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CVPR/CVPR_2018/Focal%20Visual-Text%20Attention%20for%20Visual%20Question%20Answering.pdf)]
- Attentional Separation-and-Aggregation Network for Self-supervised Depth-Pose Learning in Dynamic Scenes, CoRL 2020 ```C1M1E1L1``` [[paper](https://drive.google.com/file/d/1YJqIyvliAnBM3BYiOcewm8WdF1UN2Lcm/view)] [[website](https://corlconf.github.io/paper_487/)] [[video](https://www.youtube.com/watch?v=LGAw_nVD8MA&feature=emb_title)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CoRL/CoRL_2020/Attentional%20Separation-and-Aggregation%20Network%20for%20Self-supervised%20Depth-Pose%20Learning%20in%20Dynamic%20Scenes.pdf)]
- Layer Normalization ```C2M2E1L1``` [[paper](https://arxiv.org/pdf/1607.06450.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/others/Layer%20Normalization.pdf)]
- Multi-Modality Cross Attention Network for Image and Sentence Matching, CVPR 2020 ```C1M2E1L1``` [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wei_Multi-Modality_Cross_Attention_Network_for_Image_and_Sentence_Matching_CVPR_2020_paper.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CVPR/CVPR_2020/Multi-Modality%20Cross%20Attention%20Network%20for%20Image%20and%20Sentence%20Matching.pdf)]
- Multimodal Machine Learning: A Survey and Taxonomy, TPAMI 2019 ```M2``` [[paper](https://arxiv.org/pdf/1705.09406.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/transactions/TPAMI/TPAMI_2019/Multimodal%20Machine%20Learning-%20A%20Survey%20and%20Taxonomy.pdf)]
- Stand-Alone Self-Attention in Vision Models, NeurIPS 2019 ```C1M1E1L1``` [[paper](https://arxiv.org/pdf/1906.05909.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/NIPS/NeurIPS_2019/Stand-Alone%20Self-Attention%20in%20Vision%20Models.pdf)]
- Hierarchical Robot Navigation in Novel Environments using Rough 2-D Maps, CoRL 2020 ```C1M1E1L1``` [[paper](https://drive.google.com/file/d/11N5huogxSrWkL_dJm67KeldVEnaMHyG9/view)] [[website](https://corlconf.github.io/paper_442/)] [[video](https://www.youtube.com/watch?v=xA3CrOaHzxE&feature=emb_logo)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CoRL/CoRL_2020/Hierarchical%20Robot%20Navigation%20in%20Novel%20Environments%20using%20Rough%202-D%20Maps.pdf)]
- Multi-modal Transformer for Video Retrieval, ECCV 2020 ```C1M1E1L1``` [[paper](https://arxiv.org/pdf/2007.10639.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ECCV/ECCV_2020/Multi-modal%20Transformer%20for%20Video%20Retrieval.pdf)]
- AMC: Attention guided Multi-modal Correlation Learning for Image Search, CVPR 2017 ```C2M1E1L1``` [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chen_AMC_Attention_guided_CVPR_2017_paper.pdf)] [[code](https://github.com/kanchen-usc/AMC_ATT)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CVPR/CVPR_2017/AMC-%20Attention%20guided%20Multi-modal%20Correlation%20Learning%20for%20Image%20Search.pdf)]
- Attention? Attention!, Lil'Log ```2``` [[blog](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)]
- The Illustrated Transformer ```4``` [[blog0](http://jalammar.github.io/illustrated-transformer/)] [[blog1](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)] [[blog2](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)] [[code](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb)]
- Universal Embeddings for Spatio-Temporal Tagging of Self-Driving Logs, CoRL 2020 ```C1M1E1L1``` [[paper](https://drive.google.com/file/d/1MYWfq9d2tpJuRwFFhzUjZf-mhgQGdB_h/view)] [[website](https://corlconf.github.io/paper_205/)] [[video](https://www.youtube.com/watch?v=IeOwVqXYLck)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CoRL/CoRL_2020/Universal%20Embeddings%20for%20Spatio-Temporal%20Tagging%20of%20Self-Driving%20Logs.pdf)]
- View-Invariant Probabilistic Embedding for Human Pose, ECCV 2020 ```C2M2E1L1``` [[paper](https://arxiv.org/pdf/1912.01001.pdf)] [[website](https://ai.googleblog.com/2021/01/recognizing-pose-similarity-in-images.html)] [[code](https://github.com/google-research/google-research/tree/master/poem)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ECCV/ECCV_2020/View-Invariant%20Probabilistic%20Embedding%20for%20Human%20Pose.pdf)]
- Dual-modality Seq2Seq Network for Audio-visual Event Localization, ICASSP 2019 ```C4M4E1L1``` [[paper](https://ieeexplore.ieee.org/abstract/document/8683226?casa_token=GnTpidrt6NwAAAAA:CYYO7hq42XBhDgBsRCPLf3OyIJQi8QBKHrN_7Erf-kD6QnLjzLocaoLFBWfUW4fAQX0y6xyNjQ)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ICASSP/ICASSP_2019/Dual-modality%20Seq2Seq%20Network%20for%20Audio-visual%20Event%20Localization.pdf)]
- Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition, Sensors 2016 ```C1M1E1L1``` [[paper](https://www.mdpi.com/1424-8220/16/1/115)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/journals/Sensors/Sensors_2016/Deep%20Convolutional%20and%20LSTM%20Recurrent%20Neural%20Networks%20for%20Multimodal%20Wearable%20Activity%20Recognition.pdf)]
- Attention Is All You Need, NIPS 2017 ```C1M2E1L1``` [[paper](https://arxiv.org/pdf/1706.03762.pdf)] [[video](https://www.youtube.com/watch?v=4Bdc55j80l8)] [[code](https://github.com/tensorflow/tensor2tensor)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/NIPS/NIPS_2017/Attention%20Is%20All%20You%20Need.pdf)]
- Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks, T-RO 2020 ```C1M1E1L1``` [[paper](https://arxiv.org/pdf/1907.13098.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/transactions/T-RO/T-RO_2020/Making%20Sense%20of%20Vision%20and%20Touch-%20Learning%20Multimodal%20Representations%20for%20Contact-Rich%20Tasks.pdf)]
- Audio-Visual Event Localization in Unconstrained Videos, ECCV 2018 ```C1M1E1L1``` [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ECCV/ECCV_2018/Audio-Visual%20Event%20Localization%20in%20Unconstrained%20Videos.pdf)]
- Connecting Vision and Language with Localized Narratives, ECCV 2020 ```C1M1E1L1``` [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500630.pdf)] [[website](https://google.github.io/localized-narratives/)] [[video0](https://www.youtube.com/watch?v=_MDFe-o8qyA&feature=youtu.be)] [[video1](https://www.youtube.com/watch?v=AjuL3ljkt3Y&feature=youtu.be)] [[code](https://github.com/google/localized-narratives)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ECCV/ECCV_2020/Connecting%20Vision%20and%20Language%20with%20Localized%20Narratives.pdf)]
- Temporal Cycle-Consistency Learning, CVPR 2019 ```C2M1E1L1``` [[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Dwibedi_Temporal_Cycle-Consistency_Learning_CVPR_2019_paper.pdf)] [[website](https://sites.google.com/view/temporal-cycle-consistency)] [[video](https://www.youtube.com/watch?v=iWjjeMQmt8E)] [[code](https://github.com/google-research/google-research/tree/master/tcc)] [[colab](https://colab.research.google.com/drive/1-JYJXKoRWKcQvw5Tlacteotewpd2Bkts)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CVPR/CVPR_2019/Temporal%20Cycle-Consistency%20Learning.pdf)]
- DIRL: Domain-Invariant Representation Learning for Sim-to-Real Transfer, CoRL 2020 ```C1M1E1L1``` [[paper](https://arxiv.org/pdf/2011.07589.pdf)] [[website](https://sites.google.com/view/dirl)] [[video](https://www.youtube.com/watch?v=opC-HjSxi9E&feature=emb_logo)] [[code](https://github.com/ajaytanwani/DIRL)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CoRL/CoRL_2020/DIRL-%20Domain-Invariant%20Representation%20Learning%20for%20Sim-to-Real%20Transfer.pdf)]
- PseudoSeg: Designing Pseudo Labels for Semantic Segmentation, ICLR 2021 ```C1M1E1L1``` [[paper](https://arxiv.org/pdf/2010.09713v1.pdf)] [[forum](https://openreview.net/forum?id=-TwO99rbVRu)] [[code](https://github.com/googleinterns/wss)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ICLR/ICLR_2021/PseudoSeg-%20Designing%20Pseudo%20Labels%20for%20Semantic%20Segmentation.pdf)]
- Deep Multimodal Representation Learning: A Survey, Access 2019 ```C3M2E1L1``` [[paper](https://ieeexplore.ieee.org/document/8715409)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/journals/Access/Access_2019/Deep%20Multimodal%20Representation%20Learning-%20A%20Survey.pdf)]
- Deep Multimodal Representation Learning from Temporal Data, CVPR 2017 ```C3M2E1L1``` [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Yang_Deep_Multimodal_Representation_CVPR_2017_paper.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CVPR/CVPR_2017/Deep%20Multimodal%20Representation%20Learning%20from%20Temporal%20Data.pdf)]
- A Novel Walking Detection and Step Counting Algorithm Using Unconstrained Smartphones, Sensors 2018 ```C1M1E1L1``` [[paper](https://pdfs.semanticscholar.org/7e70/085d2f44a0739e4f04b7353455c22ce5a8f7.pdf?_ga=2.37001376.1676296708.1612717521-1206558728.1612717521)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/journals/Sensors/Sensors_2018/A%20Novel%20Walking%20Detection%20and%20Step%20Counting%20Algorithm%20Using%20Unconstrained%20Smartphones.pdf)]
- See, Hear, Explore: Curiosity via Audio-Visual Association, NeurIPS 2020 ```C3M2E2L1``` [[paper](https://papers.nips.cc/paper/2020/file/ab6b331e94c28169d15cca0cb3bbc73e-Paper.pdf)] [[website](https://vdean.github.io/audio-curiosity.html)] [[video](https://www.youtube.com/watch?v=DMiW5hwsoeo&feature=emb_logo)] [[code](https://github.com/vdean/audio-curiosity)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/NIPS/NeurIPS_2020/See%2C%20Hear%2C%20Explore-%20Curiosity%20via%20Audio-Visual%20Association.pdf)]
- Blind Image Quality Evaluation Using Perception Based Features, NCC 2015 ```C1M1E1L1``` [[paper](https://core.ac.uk/download/pdf/52170253.pdf)] [[pip](https://pypi.org/project/image-quality/)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/NCC/NCC_2015/Blind%20Image%20Quality%20Evaluation%20Using%20Perception%20Based%20Features.pdf)]
- End-to-End Low Cost Compressive Spectral Imaging with Spatial-Spectral Self-Attention, ECCV 2020 ```C3M2E1L1``` [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123680188.pdf)] [[code0](https://github.com/mengziyi64/TSA-Net)] [[code1](https://github.com/xyvirtualgroup/TSA-Net)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ECCV/ECCV_2020/End-to-End%20Low%20Cost%20Compressive%20Spectral%20Imaging%20with%20Spatial-Spectral%20Self-Attention.pdf)]
- Collaborative Deep Reinforcement Learning for Multi-Object Tracking, ECCV 2018 ```C1M1E1L1``` [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Liangliang_Ren_Collaborative_Deep_Reinforcement_ECCV_2018_paper.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ECCV/ECCV_2018/Collaborative%20Deep%20Reinforcement%20Learning%20for%20Multi-Object%20Tracking.pdf)]
- Unsupervised Correlation Analysis, CVPR 2018 ```C2M2E1L1``` [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Hoshen_Unsupervised_Correlation_Analysis_CVPR_2018_paper.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CVPR/CVPR_2018/Unsupervised%20Correlation%20Analysis.pdf)]

Y2021 Jan
- Tracking without bells and whistles, ICCV 2019 ```C1M1E1L1``` [[paper](https://arxiv.org/pdf/1903.05625.pdf)] [[code](https://github.com/phil-bergmann/tracking_wo_bnw)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ICCV/ICCV_2019/Tracking%20without%20bells%20and%20whistles.pdf)]
- FairMOT: On the Fairness of Detection and Re-Identification in Multiple Object Tracking ```C1M1E1L1``` [[paper](https://arxiv.org/pdf/2004.01888.pdf)] [[code](https://github.com/ifzhang/FairMOT)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/others/FairMOT-%20On%20the%20Fairness%20of%20Detection%20and%20Re-Identification%20in%20Multiple%20Object%20Tracking.pdf)]
- LightTrack: A Generic Framework for Online Top-Down Human Pose Tracking, CVPRW 2020 ```C3M3E1L3``` [[note](https://github.com/BryanBo-Cao/open-papernotes/blob/master/notes/confs/CVPR/CVPRW_2020/LightTrack:%20A%20Generic%20Framework%20for%20Online%20Top-Down%20Human%20Pose%20Tracking.md)] [[paper](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w70/Ning_LightTrack_A_Generic_Framework_for_Online_Top-Down_Human_Pose_Tracking_CVPRW_2020_paper.pdf)] [[code](https://github.com/Guanghan/lighttrack)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CVPR/CVPRW_2020/LightTrack-%20A%20Generic%20Framework%20for%20Online%20Top-Down%20Human%20Pose%20Tracking.pdf)]
- Unsupervised Domain Adaptation by Backpropagation, ICML 2015 ```C1M1E1L1``` [[paper](http://proceedings.mlr.press/v37/ganin15.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ICML/ICML_2015/Unsupervised%20Domain%20Adaptation%20by%20Backpropagation.pdf)]
- IONet: Learning to Cure the Curse of Drift in Inertial Odometry, AAAI 2018 ```C1M1E1L1``` [[paper](https://arxiv.org/pdf/1802.02209.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/AAAI/AAAI_2018/IONet-%20Learning%20to%20Cure%20the%20Curse%20of%20Drift%20in%20Inertial%20Odometry.pdf)]
- Deep Neural Network Based Inertial Odometry Using Low-cost Inertial Measurement Units, TMC 2019 ```C1M1E1L1``` [[paper](https://www.cs.ox.ac.uk/files/11501/DNN_IONet.pdf)] [[video](https://www.youtube.com/watch?v=L5LtE-PQuHk&feature=youtu.be)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/transactions/TMC/TMC_2019/Deep%20Neural%20Network%20Based%20Inertial%20Odometry%20Using%20Low-cost%20Inertial%20Measurement%20Units.pdf)]
- Deep-Learning-Based Pedestrian Inertial Navigation: Methods, Data Set, and On-Device Inference, IoT 2020 ```C1M1E1L1``` [[paper](https://arxiv.org/pdf/2001.04061.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/journals/IoT/IoT_2020/Deep-Learning-Based%20Pedestrian%20Inertial%20Navigation-%20Methods%2C%20Data%20Set%2C%20and%20On-Device%20Inference.pdf)]
- OxIOD: The Dataset for Deep Inertial Odometry, TR 2019 ```C5M4E1L1``` [[note](https://github.com/BryanBo-Cao/open-papernotes/blob/master/notes/others/OxIOD:%20The%20Dataset%20for%20Deep%20Inertial%20Odometry.md)] [[paper](https://arxiv.org/pdf/1809.07491.pdf)] [[dataset](https://docs.google.com/forms/d/e/1FAIpQLSfkPTV4O6__ZA30Crc7Du4y6oMFkwvaBH1acQ8nMkvf_q7Owg/viewform)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/others/OxIOD-%20The%20Dataset%20for%20Deep%20Inertial%20Odometry.pdf)]
- Plug-and-Play Algorithms for Large-scale Snapshot Compressive Imaging, CVPR 2020 ```C1M1E1L1``` [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yuan_Plug-and-Play_Algorithms_for_Large-Scale_Snapshot_Compressive_Imaging_CVPR_2020_paper.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/CVPR/CVPR_2020/Plug-and-Play%20Algorithms%20for%20Large-scale%20Snapshot%20Compressive%20Imaging.pdf)]
- Rank Minimization for Snapshot Compressive Imaging, TPAMI 2019 ```C1M1E1L1``` [[paper](https://ieeexplore.ieee.org/document/8481592)] [[code](https://github.com/liuyang12/DeSCI)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/transactions/TPAMI/TPAMI_2019/Rank%20Minimization%20for%20Snapshot%20Compressive%20Imaging.pdf)]
- λ-net: Reconstruct Hyperspectral Images from a Snapshot Measurement, ICCV 2019 ```C3M2E1L2``` [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Miao_l-Net_Reconstruct_Hyperspectral_Images_From_a_Snapshot_Measurement_ICCV_2019_paper.pdf)] [[code](https://github.com/xinxinmiao/lambda-net)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ICCV/ICCV_2019/%CE%BB-net-%20Reconstruct%20Hyperspectral%20Images%20from%20a%20Snapshot%20Measurement.pdf)]
- End-to-End Learning Framework for IMU-Based 6-DOF Odometry, Sensors 2019 ```C3M3E2L2``` [[paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6749526/)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/journals/Sensors/Sensors_2019/End-to-End%20Learning%20Framework%20for%20IMU-Based%206-DOF%20Odometry.pdf)]
- One Solution is Not All You Need: Few-Shot Extrapolation via Structured MaxEnt RL, NeurIPS 2020 ```C1M1E1L1``` [[paper](https://proceedings.neurips.cc/paper/2020/hash/5d151d1059a6281335a10732fc49620e-Abstract.html)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/NIPS/NeurIPS_2020/One%20Solution%20is%20Not%20All%20You%20Need-%20Few-Shot%20Extrapolation%20via%20Structured%20MaxEnt%20RL.pdf)]
- Multi-modal Active Learning From Human Data: A Deep Reinforcement Learning Approach, ICMI 2019 ```C1M1E1L1``` [[paper](https://arxiv.org/abs/1906.03098)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ICMI/ICMI_2019/Multi-modal%20Active%20Learning%20From%20Human%20Data-%20A%20Deep%20Reinforcement%20Learning%20Approach.pdf)]
- Adaptive Dynamic Bipartite Graph Matching: A Reinforcement Learning Approach, ICDE 2019 ```C1M1E1L1``` [[paper](https://ieeexplore.ieee.org/document/8731455)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ICDE/ICDE_2019/Adaptive%20Dynamic%20Bipartite%20Graph%20Matching-%20A%20Reinforcement%20Learning%20Approach.pdf)]
- One Way Distance: For Shape Based Similarity Search of Moving Object Trajectories, ACMGIS 2005 ```C1M1E1L1``` [[paper](https://link.springer.com/article/10.1007/s10707-007-0027-y)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/ACMGIS/ACMGIS_2005/One%20Way%20Distance-%20For%20Shape%20Based%20Similarity%20Search%20of%20Moving%20Object%20Trajectories.pdf)]
- AI-IMU Dead-Reckoning, IV 2020 ```C1M1E1L1``` [[paper](https://ieeexplore.ieee.org/document/9035481)] [[code](https://github.com/mbrossar/ai-imu-dr)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/transactions/IV/IV_2020/AI-IMU%20Dead-Reckoning.pdf)]
- On Map-Matching Vehicle Tracking Data, VLDB 2005 ```C1M1E1L1``` [[paper](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73.7466&rep=rep1&type=pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/VLDB/VLDB_2005/On%20Map-Matching%20Vehicle%20Tracking%20Data.pdf)]
- EyeFi: Fast Human Identification Through Vision and WiFi-based Trajectory Matching, DCOSS 2020 ```C1M2E1L2``` [[paper](https://ieeexplore.ieee.org/document/9183685)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/confs/DCOSS/DCOSS_2020/EyeFi-%20Fast%20Human%20Identification%20Through%20Vision%20and%20WiFi-based%20Trajectory%20Matching.pdf)]
- An Efficiently Computable Metric for Comparing Polygonal Shapes, TPAMI 1991 ```C1M1E1L1``` [[paper](http://www.cs.cornell.edu/~dph/papers/ACHKM-TPAMI-91.pdf)] [[my repo](https://github.com/BryanBo-Cao/papers/blob/master/transactions/TPAMI/TPAMI_1991/An%20Efficiently%20Computable%20Metric%20for%20Comparing%20Polygonal%20Shapes.pdf)]

[Y2020](https://github.com/BryanBo-Cao/open-papernotes/blob/master/records/Y2020.md)
[Y2019](https://github.com/BryanBo-Cao/open-papernotes/blob/master/records/Y2019.md)
